{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttsupra30/QM2/blob/main/QM_updated_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Method Overview\n",
        "**Objective**: This study examines the relationship between gambling expenditure and labour market conditions in Australia, focusing on unemployment rates across eight regions and at the national level. The analysis proceeds in two stages:\n",
        "\n",
        "**Panel regression** to identify robust **correlations** while controlling for unobserved regional heterogeneity.\n",
        "\n",
        "**Granger causality analysis** to examine lead‚Äìlag dynamics and temporal **causation**.\n",
        "\n",
        "This two-step approach allows the study to separate contemporaneous association from dynamic predictive causality."
      ],
      "metadata": {
        "id": "RtXDxdfXrpFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data\n",
        "**1.1 Unit of Analysis**\n",
        "\n",
        "Cross-sectional unit: Australian regions $i = ACT, NSW, \\dots, WA$\n",
        "\n",
        "Time unit: annual observations $t=1,\\dots,T$\n",
        "\n",
        "Balanced panel: each region observed over the same time span\n",
        "\n",
        "**1.2 Key Variables**\n",
        "\n",
        "*  Dependent or independent relies on the test direction\n",
        "\n",
        "*  $Gambling_t^{(i)}$ : real per-capita gambling expenditure $(\\$)$\n",
        "\n",
        "*  $Unemp_t^{(i)}$ : regional unemployment rate $(\\%)$\n",
        "\n",
        "**1.3 Transformations**\n",
        "\n",
        "$Gambling_t^{(i)} ‚Üí ln(Gambling_t^{(i)})$\n",
        "\n",
        "**1.4 Control variables ($X_t^{(i)}$):**\n",
        "\n",
        "Quarterly Population Estimates (Persons)\n",
        "\n",
        "Wage price index"
      ],
      "metadata": {
        "id": "7GL_ghYfsH6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "!pip install linearmodels\n",
        "from linearmodels.panel import PanelOLS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj2YO2C3ztms",
        "outputId": "d42713e2-7f2b-4c1e-f021-7943b731d863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting linearmodels\n",
            "  Downloading linearmodels-7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from linearmodels) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from linearmodels) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from linearmodels) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from linearmodels) (0.14.6)\n",
            "Collecting mypy_extensions>=0.4 (from linearmodels)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyhdfe>=0.1 (from linearmodels)\n",
            "  Downloading pyhdfe-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting formulaic>=1.2.1 (from linearmodels)\n",
            "  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=1.2.1->linearmodels)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=1.2.1->linearmodels) (2.13.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=1.2.1->linearmodels) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=1.2.1->linearmodels) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->linearmodels) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->linearmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->linearmodels) (2025.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->linearmodels) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->linearmodels) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->linearmodels) (1.17.0)\n",
            "Downloading linearmodels-7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pyhdfe-0.2.0-py3-none-any.whl (19 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: mypy_extensions, interface-meta, pyhdfe, formulaic, linearmodels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ctqedO7kzuZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "df = pd.read_csv('QM2.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_neQ_9eTz1hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert year columns\n",
        "df.dropna(subset=['Year'], inplace=True)\n",
        "df['year'] = df['Year'].str[-2:].astype(int) + 2000\n",
        "df.loc[df['year'] > 2025, 'year'] -= 100\n",
        "df"
      ],
      "metadata": {
        "id": "7zu-Gr110tQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relabel the columns\n",
        "STATE = \"State\"\n",
        "YEAR  = \"year\"\n",
        "GAMB  = \"Real per capita total gambling expenditure value ($)\"\n",
        "UNEMP = \"Unemployment rate (%)\"\n",
        "WPI   = \"Wage price index\"\n",
        "POP   = \"Final consumption expenditure minus net loss from gambling ( Millions $)\"\n",
        "\n",
        "# Keep only necessary columns\n",
        "df = df[[STATE, YEAR, GAMB, UNEMP, WPI, POP]].copy()\n",
        "\n",
        "# Ensure numeric data of all variables\n",
        "df[[GAMB, UNEMP, WPI, POP]] = df[[GAMB, UNEMP, WPI, POP]].apply(\n",
        "    pd.to_numeric, errors=\"coerce\"\n",
        ")\n",
        "\n",
        "# Log gambling (must be > 0)\n",
        "df = df[df[GAMB] > 0]\n",
        "df[\"log_gambling\"] = np.log(df[GAMB])\n",
        "\n",
        "# Log controls (must be > 0)\n",
        "df = df[df[POP] > 0]\n",
        "df[\"log_pop\"] = np.log(df[POP])\n",
        "\n",
        "# Drop missing and set panel index\n",
        "df = df.dropna(subset=[STATE, YEAR, \"log_gambling\", UNEMP, WPI, \"log_pop\"])\n",
        "df = df.set_index([STATE, YEAR]).sort_index()\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "5hzA3rL00SCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Models\n",
        "# 3.1 Time-series OLS + Panel Regression\n",
        "**3.1.A Model A: Gambling leads unemployment**\n",
        "\n",
        "*   Test of gambling ‚Üí later unemployment\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x8HtZjbAtQOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model A1: National time-series OLS (Australia as a whole)**"
      ],
      "metadata": {
        "id": "tSBj4i3tTnR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "Unemp_t\n",
        "=\n",
        "\\alpha\n",
        "+\\sum_{k=0}^{p}\\beta_k\\,\\ln(Gambling_{t-k})\n",
        "+\\delta_2 \\ln(Pop_t)\n",
        "+\\delta_3 WPI_t\n",
        "+\\varepsilon_t\n",
        "$$"
      ],
      "metadata": {
        "id": "4_ZdzEB8TwlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model A2: Single-region time-series OLS** (e.g. NSW only)\n",
        "\n",
        "* Same equation - just applied to one region."
      ],
      "metadata": {
        "id": "ojrJAyK2T4xK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "Unemp_{i,t}\n",
        "=\n",
        "\\alpha\n",
        "+\\sum_{k=0}^{p}\\beta_k\\,\\ln(Gambling_{i,t-k})\n",
        "+\\delta_2 \\ln(Pop_{i,t})\n",
        "+\\delta_3 WPI_{i,t}\n",
        "+\\varepsilon_{i,t}\n",
        "$$"
      ],
      "metadata": {
        "id": "plXfoiH-UOTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "H_0 &: \\beta_0 = \\beta_1 = \\cdots = \\beta_p = 0\n",
        "&& \\text{(Gambling expenditure has no association with unemployment)} \\\\\n",
        "H_1 &: \\exists \\; k \\in \\{0,\\dots,p\\} \\text{ such that } \\beta_k \\neq 0\n",
        "&& \\text{(Gambling expenditure is associated with unemployment at some lag)}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "uV52bb7OWkPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both two times series OLS test for ‚ÄúDoes gambling correlate with later unemployment within this specific region over time?‚Äù"
      ],
      "metadata": {
        "id": "npEd3vbwWFI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ts_ols_modelA(ts_df, *, year_col=YEAR, p=1):\n",
        "\n",
        "    d = (\n",
        "        ts_df[[year_col, UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "        .dropna()\n",
        "        .sort_values(year_col)\n",
        "        .copy()\n",
        "    )\n",
        "\n",
        "    # Lag gambling INCLUDING contemporaneous term (k = 0)\n",
        "    for k in range(0, p + 1):\n",
        "        d[f\"g_L{k}\"] = d[\"log_gambling\"].shift(k)\n",
        "\n",
        "    rhs = (\n",
        "        [f\"g_L{k}\" for k in range(0, p + 1)]\n",
        "        + [ \"log_pop\", WPI]\n",
        "    )\n",
        "\n",
        "    d = d.dropna(subset=[UNEMP] + rhs)\n",
        "\n",
        "    y = d[UNEMP].astype(float)\n",
        "    X = sm.add_constant(d[rhs].astype(float))\n",
        "\n",
        "    res = sm.OLS(y, X).fit(\n",
        "        cov_type=\"HAC\",\n",
        "        cov_kwds={\"maxlags\": p}\n",
        "    )\n",
        "\n",
        "    return res, d\n"
      ],
      "metadata": {
        "id": "JnBpsaQXtXCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call National level\n",
        "df_flat = df.reset_index()\n",
        "\n",
        "nat = (\n",
        "    df_flat\n",
        "    .groupby(YEAR)[[UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "res_nat, used_nat = ts_ols_modelA(nat, year_col=YEAR, p=5)\n",
        "print(res_nat.summary())\n"
      ],
      "metadata": {
        "id": "GA6pKE-oteb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call National level Exclude Northern Territory\n",
        "df_flat_noNT = df_flat[df_flat[\"State\"] != \"NT\"].copy()\n",
        "# National series excluding NT (average across remaining states)\n",
        "nat_noNT = (\n",
        "    df_flat_noNT\n",
        "    .groupby(YEAR)[[UNEMP, \"log_gambling\",\"log_pop\", WPI]]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "res_nat_noNT, used_nat_noNT = ts_ols_modelA(\n",
        "    nat_noNT,\n",
        "    year_col=YEAR,\n",
        "    p=5\n",
        ")\n",
        "\n",
        "print(res_nat_noNT.summary())\n"
      ],
      "metadata": {
        "id": "enKBAyS-vG4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call Regional level\n",
        "region_nsw = df_flat[df_flat[\"State\"] == \"NSW\"][\n",
        "    [YEAR, UNEMP, \"log_gambling\", \"log_pop\", WPI]\n",
        "]\n",
        "\n",
        "res_nsw, used_nsw = ts_ols_modelA(region_nsw, year_col=YEAR, p=3)\n",
        "print(res_nsw.summary())"
      ],
      "metadata": {
        "id": "zdWutcz5urXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKE ONE RESULT TABLE (National, 8 states, National excl NT) ======\n",
        "\n",
        "from statsmodels.iolib.summary2 import summary_col\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def cumulative_gambling_effect(res, p):\n",
        "    return sum(float(res.params.get(f\"g_L{k}\", 0.0)) for k in range(0, p + 1))\n",
        "\n",
        "def wald_pvalue_gambling_raw(res, p):\n",
        "    terms = [f\"g_L{k}\" for k in range(0, p + 1)]\n",
        "    hypothesis = \" = \".join(terms) + \" = 0\"\n",
        "    wt = res.wald_test(hypothesis, scalar=True)  # scalar=True avoids FutureWarning\n",
        "    return float(wt.pvalue)\n",
        "\n",
        "def format_p(pval, decimals=6):\n",
        "    # raw numeric p-value, formatted consistently; if extremely tiny, show scientific\n",
        "    if pval == 0.0:\n",
        "        return \"0\"\n",
        "    if pval < 10**(-decimals):\n",
        "        return f\"{pval:.2e}\"\n",
        "    return f\"{pval:.{decimals}f}\"\n",
        "\n",
        "# ---------- settings ----------\n",
        "P = 5   # lag length used in ts_ols_modelA (must match your estimation)\n",
        "EXCL = \"NT\"      # exclude NT for the robustness national series\n",
        "\n",
        "# ---------- flatten panel ----------\n",
        "df_flat = df.reset_index()\n",
        "\n",
        "# ---------- National (All) ----------\n",
        "nat_all = (\n",
        "    df_flat.groupby(YEAR)[[UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "model_nat_all, _ = ts_ols_modelA(nat_all, year_col=YEAR, p=P)\n",
        "\n",
        "# ---------- State models ----------\n",
        "state_models, state_names = [], []\n",
        "for st in sorted(df_flat[\"State\"].dropna().unique()):\n",
        "    sub = df_flat[df_flat[\"State\"] == st][\n",
        "        [YEAR, UNEMP, \"log_gambling\",  \"log_pop\", WPI]\n",
        "    ]\n",
        "    res, _ = ts_ols_modelA(sub, year_col=YEAR, p=P)\n",
        "    state_models.append(res)\n",
        "    state_names.append(st)\n",
        "\n",
        "# ---------- National (exclude NT) ----------\n",
        "nat_excl = (\n",
        "    df_flat[df_flat[\"State\"] != EXCL]\n",
        "    .groupby(YEAR)[[UNEMP, \"log_gambling\",  \"log_pop\", WPI]]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "model_nat_excl, _ = ts_ols_modelA(nat_excl, year_col=YEAR, p=P)\n",
        "\n",
        "# ---------- build summary_col table ----------\n",
        "models = [model_nat_all] + state_models + [model_nat_excl]\n",
        "names  = [\"National (All)\"] + state_names + [f\"National (excl {EXCL})\"]\n",
        "\n",
        "regressor_order = (\n",
        "    [\"const\"]\n",
        "    + [f\"g_L{k}\" for k in range(0, P + 1)]\n",
        "    + [ \"log_pop\", WPI]\n",
        ")\n",
        "\n",
        "# Keep info_dict minimal to avoid duplicated lines\n",
        "table = summary_col(\n",
        "    models,\n",
        "    stars=True,\n",
        "    float_format=\"%0.3f\",\n",
        "    model_names=names,\n",
        "    regressor_order=regressor_order,\n",
        "    info_dict={\n",
        "        \"N\": lambda x: f\"{int(x.nobs)}\"\n",
        "    },\n",
        ")\n",
        "\n",
        "# ---------- append extra rows (aligned as normal rows) ----------\n",
        "df_table = table.tables[0]\n",
        "\n",
        "cum_vals = [f\"{cumulative_gambling_effect(m, P):.3f}\" for m in models]\n",
        "wald_vals = [format_p(wald_pvalue_gambling_raw(m, P), decimals=6) for m in models]\n",
        "\n",
        "df_table.loc[f\"Cumulative gambling effect (sum g_L0..g_L{P})\"] = cum_vals\n",
        "df_table.loc[f\"Wald p-value (H0: g_L0..g_L{P} = 0)\"] = wald_vals\n",
        "\n",
        "# ---------- print in a ‚Äúparallel‚Äù aligned way (avoid wrapping) ----------\n",
        "with pd.option_context(\n",
        "    \"display.width\", 4000,\n",
        "    \"display.max_columns\", None,\n",
        "    \"display.max_colwidth\", None\n",
        "):\n",
        "    print(df_table.to_string())\n"
      ],
      "metadata": {
        "id": "NTvxGILc4WWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Sensitivity test over lag length p ----------\n",
        "\n",
        "P_MAX = 8   # or whatever maximum lag you want\n",
        "\n",
        "rows = []\n",
        "\n",
        "for p in range(0, P_MAX + 1):\n",
        "\n",
        "    # run NATIONAL model (example: national average series)\n",
        "    res, used = ts_ols_modelA(nat_all, year_col=YEAR, p=p)\n",
        "\n",
        "    # cumulative effect\n",
        "    cum_eff = cumulative_gambling_effect(res, p)\n",
        "\n",
        "    # Wald test\n",
        "    terms = [f\"g_L{k}\" for k in range(0, p + 1)]\n",
        "    hypothesis = \" = \".join(terms) + \" = 0\"\n",
        "    wt = res.wald_test(hypothesis, scalar=True)\n",
        "\n",
        "    rows.append({\n",
        "        \"k\": p,\n",
        "        \"Cumulative gambling effect\": cum_eff,\n",
        "        \"Wald stat\": float(wt.statistic),\n",
        "        \"Wald p-value\": float(wt.pvalue),\n",
        "        \"N\": int(res.nobs),\n",
        "    })\n",
        "\n",
        "# build table\n",
        "sens_table = pd.DataFrame(rows).set_index(\"p\")\n",
        "\n",
        "# pretty print\n",
        "with pd.option_context(\n",
        "    \"display.float_format\", \"{:.6g}\".format,\n",
        "    \"display.width\", 2000\n",
        "):\n",
        "    print(sens_table)\n"
      ],
      "metadata": {
        "id": "Px1Js7W5h6kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# ----------------------------\n",
        "# ASSUMES you already have:\n",
        "# df_flat with columns: [STATE, YEAR, UNEMP, log_gambling, log_pop, WPI]\n",
        "# and constants:\n",
        "# STATE=\"State\", YEAR=\"year\", UNEMP=\"Unemployment rate (%)\", WPI=\"Wage price index\"\n",
        "# ----------------------------\n",
        "\n",
        "def ts_ols_modelA(ts_df, *, year_col, p):\n",
        "    \"\"\"\n",
        "    Unemployment_t ~ g_L0..g_Lp + log_pop + WPI\n",
        "    HAC SEs with maxlags=p\n",
        "    Returns (res, d_used) where d_used includes the lag columns.\n",
        "    \"\"\"\n",
        "    d = (\n",
        "        ts_df[[year_col, UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "        .dropna()\n",
        "        .sort_values(year_col)\n",
        "        .copy()\n",
        "    )\n",
        "\n",
        "    for k in range(0, p + 1):\n",
        "        d[f\"g_L{k}\"] = d[\"log_gambling\"].shift(k)\n",
        "\n",
        "    rhs = [f\"g_L{k}\" for k in range(0, p + 1)] + [\"log_pop\", WPI]\n",
        "    d = d.dropna(subset=[UNEMP] + rhs)\n",
        "\n",
        "    y = d[UNEMP].astype(float)\n",
        "    X = sm.add_constant(d[rhs].astype(float))\n",
        "\n",
        "    res = sm.OLS(y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": p})\n",
        "    return res, d\n",
        "\n",
        "\n",
        "def plot_actual_vs_fitted_modelA(ts_df, label, *, year_col, p, fig_number):\n",
        "    \"\"\"\n",
        "    Plots Actual vs Fitted unemployment from Model A\n",
        "    \"\"\"\n",
        "    res, d_used = ts_ols_modelA(ts_df, year_col=year_col, p=p)\n",
        "\n",
        "    rhs = [f\"g_L{k}\" for k in range(0, p + 1)] + [\"log_pop\", WPI]\n",
        "    X_used = sm.add_constant(d_used[rhs].astype(float))\n",
        "    fitted = res.predict(X_used)\n",
        "\n",
        "    plt.figure(figsize=(9, 4.5))\n",
        "    plt.plot(\n",
        "        d_used[year_col],\n",
        "        d_used[UNEMP],\n",
        "        marker=\"o\",\n",
        "        label=\"Actual unemployment\"\n",
        "    )\n",
        "    plt.plot(\n",
        "        d_used[year_col],\n",
        "        fitted,\n",
        "        marker=\"o\",\n",
        "        linestyle=\"--\",\n",
        "        label=\"Fitted (OLS model)\"\n",
        "    )\n",
        "\n",
        "    plt.title(\n",
        "        f\"Figure {fig_number}: {label} : OLS Model (k={p}), gambling ‚Üí unemployment\"\n",
        "    )\n",
        "    plt.xlabel(\"Year\")\n",
        "    plt.ylabel(\"Unemployment rate (%)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "# ---------- RUN EVERYTHING ----------\n",
        "def run_all_plots_modelA(df_flat, *, p=2, section=1):\n",
        "    fig_counter = 1\n",
        "\n",
        "    # National (all states)\n",
        "    nat_all = (\n",
        "        df_flat\n",
        "        .groupby(YEAR)[[UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    plot_actual_vs_fitted_modelA(\n",
        "        nat_all,\n",
        "        \"National\",\n",
        "        year_col=YEAR,\n",
        "        p=p,\n",
        "        fig_number=f\"{section}.{fig_counter}\"\n",
        "    )\n",
        "    fig_counter += 1\n",
        "\n",
        "    # State-level plots\n",
        "    states = sorted(df_flat[STATE].dropna().unique())\n",
        "    for st in states:\n",
        "        st_df = df_flat[df_flat[STATE] == st][\n",
        "            [YEAR, UNEMP, \"log_gambling\", \"log_pop\", WPI]\n",
        "        ].copy()\n",
        "\n",
        "        plot_actual_vs_fitted_modelA(\n",
        "            st_df,\n",
        "            st,\n",
        "            year_col=YEAR,\n",
        "            p=p,\n",
        "            fig_number=f\"{section}.{fig_counter}\"\n",
        "        )\n",
        "        fig_counter += 1\n",
        "\n",
        "\n",
        "# Example call\n",
        "df_flat = df.reset_index() # Re-initialize df_flat\n",
        "run_all_plots_modelA(df_flat, p=2, section=1)"
      ],
      "metadata": {
        "id": "jUndTu0wNGjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# ----------------------------\n",
        "# ASSUMES you already have:\n",
        "# df_flat with columns: [STATE, YEAR, UNEMP, log_gambling, log_pop, WPI]\n",
        "# ----------------------------\n",
        "\n",
        "def ts_ols_modelB(ts_df, *, year_col, p):\n",
        "    \"\"\"\n",
        "    log_gambling_t ~ u_L0..u_Lp + log_pop + WPI\n",
        "    HAC SEs with maxlags=p\n",
        "    Returns (res, d_used) where d_used includes the lag columns.\n",
        "    \"\"\"\n",
        "    d = (\n",
        "        ts_df[[year_col, UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "        .dropna()\n",
        "        .sort_values(year_col)\n",
        "        .copy()\n",
        "    )\n",
        "\n",
        "    for k in range(0, p + 1):\n",
        "        d[f\"u_L{k}\"] = d[UNEMP].shift(k)\n",
        "\n",
        "    rhs = [f\"u_L{k}\" for k in range(0, p + 1)] + [\"log_pop\", WPI]\n",
        "    d = d.dropna(subset=[\"log_gambling\"] + rhs)\n",
        "\n",
        "    y = d[\"log_gambling\"].astype(float)\n",
        "    X = sm.add_constant(d[rhs].astype(float))\n",
        "\n",
        "    res = sm.OLS(y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": p})\n",
        "    return res, d\n",
        "\n",
        "\n",
        "def plot_actual_vs_fitted_modelB(ts_df, label, *, year_col, p):\n",
        "    \"\"\"\n",
        "    Plots Actual log gambling vs Fitted log gambling from Model B.\n",
        "    \"\"\"\n",
        "    res, d_used = ts_ols_modelB(ts_df, year_col=year_col, p=p)\n",
        "\n",
        "    rhs = [f\"u_L{k}\" for k in range(0, p + 1)] + [\"log_pop\", WPI]\n",
        "    X_used = sm.add_constant(d_used[rhs].astype(float))\n",
        "    fitted = res.predict(X_used)\n",
        "\n",
        "    plt.figure(figsize=(9, 4.5))\n",
        "    plt.plot(d_used[year_col], d_used[\"log_gambling\"], marker=\"o\", label=\"Actual log gambling\")\n",
        "    plt.plot(d_used[year_col], fitted, marker=\"o\", linestyle=\"--\", label=\"Fitted (OLS Model)\")\n",
        "    plt.title(f\"{label} : OLS Model (k={p}) : unemployment ‚Üí gambling\")\n",
        "    plt.xlabel(\"Year\")\n",
        "    plt.ylabel(\"Log gambling expenditure (per capita)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# RUN EVERYTHING\n",
        "# ----------------------------\n",
        "def run_all_plots_modelB(df_flat, *, p=2, exclude_nt=True):\n",
        "    # National (All)\n",
        "    nat_all = (\n",
        "        df_flat.groupby(YEAR)[[UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "    plot_actual_vs_fitted_modelB(nat_all, \"National (All)\", year_col=YEAR, p=p)\n",
        "\n",
        "    # National (excl NT)\n",
        "    if exclude_nt:\n",
        "        nat_excl = (\n",
        "            df_flat[df_flat[STATE] != \"NT\"]\n",
        "            .groupby(YEAR)[[UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "            .mean()\n",
        "            .reset_index()\n",
        "        )\n",
        "        plot_actual_vs_fitted_modelB(nat_excl, \"National (excl NT)\", year_col=YEAR, p=p)\n",
        "\n",
        "    # States\n",
        "    states = sorted(df_flat[STATE].dropna().unique())\n",
        "    for st in states:\n",
        "        st_df = df_flat[df_flat[STATE] == st][[YEAR, UNEMP, \"log_gambling\", \"log_pop\", WPI]].copy()\n",
        "        plot_actual_vs_fitted_modelB(st_df, st, year_col=YEAR, p=p)\n",
        "\n",
        "\n",
        "# Example call:\n",
        "# run_all_plots_modelB(df_flat, p=2, exclude_nt=True)\n",
        "run_all_plots_modelB(df_flat, p=2)"
      ],
      "metadata": {
        "id": "FjuErYJEOvEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intepret the Coefficient**\n",
        "\n",
        "Note: Here I deliberately set $k$ starting from $0$, so that when $k=0$ we capture the contemporaneous effect, that is, how unemployment and gambling move within the same year."
      ],
      "metadata": {
        "id": "Vp7Tu94XKl4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updated: I've included the cumulative gambling effect row and Wald p-value to help the analysis."
      ],
      "metadata": {
        "id": "lmn2AV_c7n8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model A3: 8-region panel** (main regional analysis)"
      ],
      "metadata": {
        "id": "4UiqpTVMU-7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "Unemp_t\n",
        "=\n",
        "\\alpha\n",
        "+\\sum_{k=0}^{p}\\beta_k\\,\\ln(Gambling_{t-k})\n",
        "+\\delta_2 \\ln(Pop_t)\n",
        "+\\delta_3 WPI_t\n",
        "+\\mu_i\n",
        "+\\lambda_t\n",
        "+\\eta_{i,t}\n",
        "$$"
      ],
      "metadata": {
        "id": "cyaSk_l7VrOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "H_0 &: \\sum_{k=0}^{p}\\theta_k = 0,\n",
        "&& k = 0,1,\\dots,p\n",
        "&& \\text{(No overall association over the lag window)} \\\\\n",
        "H_1 &: \\sum_{k=0}^{p}\\theta_k \\neq 0,\n",
        "&& k = 0,1,\\dots,p\n",
        "&& \\text{(Overall association over the lag window)}\n",
        "\\end{align}\n"
      ],
      "metadata": {
        "id": "j9cO-gibX7vC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** We only use panel regression when we have both **cross-sectional** and **time-series** data. In this case, it only works when we include all 8 regions together with their time-series data.\n",
        "\n",
        "In the previous section, I use time-series OLS because we do not use the cross-sectional dimension and instead examine one region at a time.\n"
      ],
      "metadata": {
        "id": "ImYBfenFWyr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Panel model tells ‚ÄúWithin regions, does gambling lead unemployment **after accounting for regional differences and national shocks?**‚Äù"
      ],
      "metadata": {
        "id": "uMTkn2WZY8Ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The error terms**\n",
        "\n",
        "**$\\bf 1. \\; \\mu^{(i)}$ :** Region fixed effects $:=$ everything about that region that does NOT change over time\n",
        "\n",
        "‚ÄúControls for things that make $NSW$ permanently different from $WA$.‚Äù\n",
        "\n",
        "Examples: Cultural attitudes toward gambling, Long-run industry structure (e.g. mining-heavy $WA$), Historical labour-market characteristics, etc.\n",
        "\n",
        "These factors differ across regions but are constant over time within each region.\n",
        "\n",
        "**$\\bf 2. \\; \\lambda_t$ :** Year fixed effects $:=$ everything that affects all regions in year\n",
        "\n",
        "‚ÄúControls for things that affect all regions in a given year, like COVID.‚Äù\n",
        "\n",
        "Examples: National recessions / booms, COVID, Interest-rate cycles, etc.\n",
        "\n",
        "So if unemployment and gambling both spike in 2020: that variation is absorbed by ùúÜ not attributed to gambling causing unemployment\n",
        "\n",
        "**$\\bf 3. \\; \\epsilon_t^{(i)}$ :** Idiosyncratic shocks $:=$ unexpected region-year noise\n",
        "\n",
        "‚ÄúEverything else we can't explain.‚Äù\n",
        "\n",
        "Examples: A local factory closure, A temporary regional event, Measurement error, etc."
      ],
      "metadata": {
        "id": "2T9irSf0ZSjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def panel_fe_modelA(df_panel, *, p=1):\n",
        "    d = df_panel.copy()\n",
        "\n",
        "    # Ensure MultiIndex (STATE, YEAR)\n",
        "    if not isinstance(d.index, pd.MultiIndex):\n",
        "        d = d.set_index([STATE, YEAR]).sort_index()\n",
        "    else:\n",
        "        d = d.sort_index()\n",
        "\n",
        "    # Required columns\n",
        "    required = [UNEMP, \"log_gambling\", \"log_pop\", WPI]\n",
        "    missing = [c for c in required if c not in d.columns]\n",
        "    if missing:\n",
        "        raise KeyError(f\"Missing columns in df_panel: {missing}\")\n",
        "\n",
        "    # Build gambling lags within state: k = 0..p\n",
        "    for k in range(0, p + 1):\n",
        "        d[f\"g_L{k}\"] = d.groupby(level=0)[\"log_gambling\"].shift(k)\n",
        "\n",
        "    # Regressors: gambling lags + controls\n",
        "    g_terms = [f\"g_L{k}\" for k in range(0, p + 1)]\n",
        "    rhs = g_terms + [\"log_pop\", WPI]\n",
        "\n",
        "    # Drop missing due to lags\n",
        "    d = d[[UNEMP] + rhs].dropna()\n",
        "\n",
        "    y = d[UNEMP].astype(float)\n",
        "    X = d[rhs].astype(float)\n",
        "\n",
        "    mod = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
        "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
        "\n",
        "    # Cumulative effect: sum_{k=0..p} beta_k\n",
        "    cum_effect = float(res.params[g_terms].sum())\n",
        "\n",
        "    # Joint Wald test: H0: g_L0 = ... = g_Lp = 0\n",
        "    param_names = list(res.params.index)\n",
        "    K = len(param_names)\n",
        "    R = np.zeros((len(g_terms), K))\n",
        "    for i, term in enumerate(g_terms):\n",
        "        R[i, param_names.index(term)] = 1.0\n",
        "    q = np.zeros(len(g_terms))\n",
        "\n",
        "    wald = res.wald_test(R, q)\n",
        "    wald_stat = float(wald.stat)\n",
        "    wald_pval = float(wald.pval)\n",
        "\n",
        "    extra = pd.DataFrame(\n",
        "        {\n",
        "            \"Cumulative gambling effect\": [cum_effect],\n",
        "            \"Wald stat (H0: g_L0..g_Lp = 0)\": [wald_stat],\n",
        "            \"Wald p-value (H0: g_L0..g_Lp = 0)\": [wald_pval],\n",
        "            \"N\": [int(res.nobs)],\n",
        "            \"p\": [int(p)],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return res, extra\n",
        "\n"
      ],
      "metadata": {
        "id": "1WWpdZhwZdw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- HOW TO CALL THE PANEL (choose one p) ----\n",
        "# Example: run the panel with p = 3\n",
        "res_panel, extra_panel = panel_fe_modelA(df, p=3)\n",
        "\n",
        "# regression output\n",
        "print(res_panel.summary)\n",
        "\n",
        "# diagnostics as separate rows (vertical)\n",
        "print(extra_panel.T.rename(columns={0: \"value\"}))"
      ],
      "metadata": {
        "id": "gjtuxlRwZ307"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PART 2 ‚Äî Sensitivity test over multiple p\n",
        "def sensitivity_test_panelA(df_panel, p_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]):\n",
        "    rows = []\n",
        "\n",
        "    for p in p_list:\n",
        "        _, extra = panel_fe_modelA(df_panel, p=p)\n",
        "        rows.append(extra)\n",
        "\n",
        "    out = pd.concat(rows, ignore_index=True).set_index(\"p\")\n",
        "    return out"
      ],
      "metadata": {
        "id": "hVKxmEl0Zq5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- HOW TO CALL THE SENSITIVITY TEST ----\n",
        "# Example: test p = 1..5\n",
        "sens = sensitivity_test_panelA(df, p_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
        "sens"
      ],
      "metadata": {
        "id": "iWuBm4JgZ9Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1.B Model B: Gambling lags unemployment**\n",
        "\n",
        "Test of unemployment ‚Üí later gambling\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jbDlNXx-xApu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part should be really easy to understand if you understand 3.1.A, we are just switching the dependent and independent variables.\n",
        "Therefore, I'll simplify the explanation ;)\n",
        "\n"
      ],
      "metadata": {
        "id": "O9O46wk-cDTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model B1 and B2: Time-series OLS run at National and Regional level**"
      ],
      "metadata": {
        "id": "2EptPwObcjlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\ln(Gambling_{i,t})\n",
        "=\n",
        "\\alpha\n",
        "+\\sum_{k=0}^{p}\\theta_k\\,Unemp_{i,t-k}\n",
        "+\\delta_2 \\ln(Pop_{i,t})\n",
        "+\\delta_3 WPI_{i,t}\n",
        "+\\varepsilon_{i,t}\n",
        "$$"
      ],
      "metadata": {
        "id": "l-nVxeM_diG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "H_0 &: \\beta_0 = \\beta_1 = \\cdots = \\beta_p = 0,\n",
        "\\qquad k \\in \\{0,1,\\dots,p\\}\n",
        "&& \\text{(Gambling expenditure has no association with unemployment)} \\\\\n",
        "H_1 &: \\exists\\, k \\in \\{0,1,\\dots,p\\} \\text{ such that } \\beta_k \\neq 0\n",
        "&& \\text{(Gambling expenditure is associated with unemployment over the lag window)}\n",
        "\\end{align}\n"
      ],
      "metadata": {
        "id": "Le3lLU0DZFO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model B (time-series OLS): log_gambling_t on lags of unemployment + controls (log_awe, log_pop, WPI)\n",
        "\n",
        "def ts_ols_modelB(ts_df, *, year_col=YEAR, p=1):\n",
        "    \"\"\"\n",
        "    log_gambling_t ~ u_{t}, u_{t-1}, ..., u_{t-p} + log_awe_t + log_pop_t + WPI_t\n",
        "    HAC (Newey‚ÄìWest) SEs with maxlags = p\n",
        "    \"\"\"\n",
        "\n",
        "    d = (\n",
        "        ts_df[[year_col, UNEMP, \"log_gambling\", \"log_pop\", WPI]]\n",
        "        .dropna()\n",
        "        .sort_values(year_col)\n",
        "        .copy()\n",
        "    )\n",
        "\n",
        "    # Lag unemployment: k = 0..p\n",
        "    for k in range(0, p + 1):\n",
        "        d[f\"u_L{k}\"] = d[UNEMP].shift(k)\n",
        "\n",
        "    rhs = [f\"u_L{k}\" for k in range(0, p + 1)] + [\"log_pop\", WPI]\n",
        "    d = d.dropna(subset=[\"log_gambling\"] + rhs)\n",
        "\n",
        "    y = d[\"log_gambling\"].astype(float)\n",
        "    X = sm.add_constant(d[rhs].astype(float))\n",
        "\n",
        "    res = sm.OLS(y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": p})\n",
        "    return res, d\n"
      ],
      "metadata": {
        "id": "lTY5GHgdD7lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call Model B1\n",
        "# National\n",
        "df_flat = df.reset_index()\n",
        "nat = df_flat.groupby(YEAR)[[UNEMP, \"log_gambling\", \"log_pop\", WPI]].mean().reset_index()\n",
        "\n",
        "res_nat_B, used_nat_B = ts_ols_modelB(nat, year_col=YEAR, p=5)# change p here\n",
        "print(res_nat_B.summary())"
      ],
      "metadata": {
        "id": "BKJs9xL8DUVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call Model B2\n",
        "# Regional\n",
        "region = df_flat[df_flat[\"State\"] == \"NSW\"][[YEAR, UNEMP, \"log_gambling\", \"log_pop\", WPI]] # change region here\n",
        "\n",
        "res_nsw_B, used_nsw_B = ts_ols_modelB(region, year_col=YEAR, p=3)# change p here\n",
        "print(res_nsw_B.summary())"
      ],
      "metadata": {
        "id": "BVhiDsJjgyRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= MODEL B RESULTS TABLE (National + 8 states + National excl NT)\n",
        "\n",
        "\n",
        "# ---- helpers ----\n",
        "def cumulative_unemp_effect(res, p):\n",
        "    return sum(float(res.params.get(f\"u_L{k}\", 0.0)) for k in range(0, p + 1))\n",
        "\n",
        "def wald_pvalue_unemp_block(res, p):\n",
        "    terms = [f\"u_L{k}\" for k in range(0, p + 1)]\n",
        "    hypothesis = \" = \".join(terms) + \" = 0\"\n",
        "    wt = res.wald_test(hypothesis, scalar=True)  # avoids FutureWarning\n",
        "    return float(wt.pvalue)\n",
        "\n",
        "def fmt_p(pval, decimals=6):\n",
        "    # raw p-value, readable (scientific if very small)\n",
        "    if pval == 0.0:\n",
        "        return \"0\"\n",
        "    if pval < 10**(-decimals):\n",
        "        return f\"{pval:.2e}\"\n",
        "    return f\"{pval:.{decimals}f}\"\n",
        "\n",
        "# ---- settings ----\n",
        "P = 5       # set lag length here (e.g., 3 if you want u_L0..u_L3)\n",
        "EXCL = \"NT\"    # exclude NT for robustness national series\n",
        "\n",
        "# ---- flatten ----\n",
        "df_flat = df.reset_index()\n",
        "\n",
        "# ---- National (All) ----\n",
        "nat_all = (\n",
        "    df_flat.groupby(YEAR)[[UNEMP, \"log_gambling\",  \"log_pop\", WPI]]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "model_nat_all, _ = ts_ols_modelB(nat_all, year_col=YEAR, p=P)\n",
        "\n",
        "# ---- Each state ----\n",
        "state_models, state_names = [], []\n",
        "for st in sorted(df_flat[\"State\"].dropna().unique()):\n",
        "    sub = df_flat[df_flat[\"State\"] == st][\n",
        "        [YEAR, UNEMP, \"log_gambling\",  \"log_pop\", WPI]\n",
        "    ]\n",
        "    res, _ = ts_ols_modelB(sub, year_col=YEAR, p=P)\n",
        "    state_models.append(res)\n",
        "    state_names.append(st)\n",
        "\n",
        "# ---- National (exclude NT) ----\n",
        "nat_excl = (\n",
        "    df_flat[df_flat[\"State\"] != EXCL]\n",
        "    .groupby(YEAR)[[UNEMP, \"log_gambling\",  \"log_pop\", WPI]]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "model_nat_excl, _ = ts_ols_modelB(nat_excl, year_col=YEAR, p=P)\n",
        "\n",
        "# ---- Build table ----\n",
        "models = [model_nat_all] + state_models + [model_nat_excl]\n",
        "names  = [\"National (All)\"] + state_names + [f\"National (excl {EXCL})\"]\n",
        "\n",
        "regressor_order = (\n",
        "    [\"const\"]\n",
        "    + [f\"u_L{k}\" for k in range(0, P + 1)]\n",
        "    + [ \"log_pop\", WPI]\n",
        ")\n",
        "\n",
        "table = summary_col(\n",
        "    models,\n",
        "    stars=True,\n",
        "    float_format=\"%0.3f\",\n",
        "    model_names=names,\n",
        "    regressor_order=regressor_order,\n",
        "    info_dict={\n",
        "        \"R-squared\": lambda x: f\"{x.rsquared:.3f}\",\n",
        "        \"R-squared Adj.\": lambda x: f\"{x.rsquared_adj:.3f}\",\n",
        "        \"N\": lambda x: f\"{int(x.nobs)}\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# ---- Append extra rows ----\n",
        "df_table = table.tables[0]\n",
        "\n",
        "cum_vals  = [f\"{cumulative_unemp_effect(m, P):.3f}\" for m in models]\n",
        "wald_pvals = [fmt_p(wald_pvalue_unemp_block(m, P), decimals=6) for m in models]\n",
        "\n",
        "df_table.loc[f\"Cumulative unemployment effect (sum u_L0..u_L{P})\"] = cum_vals\n",
        "df_table.loc[f\"Wald p-value (H0: u_L0..u_L{P} = 0)\"] = wald_pvals\n",
        "\n",
        "# ---- Print aligned ----\n",
        "with pd.option_context(\"display.width\", 4000, \"display.max_columns\", None, \"display.max_colwidth\", None):\n",
        "    print(df_table.to_string())\n"
      ],
      "metadata": {
        "id": "8-_RBWwlF4kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Sensitivity test over lag length p ----------\n",
        "\n",
        "P_MAX = 10   # or whatever maximum lag you want\n",
        "\n",
        "rows = []\n",
        "\n",
        "for p in range(0, P_MAX + 1):\n",
        "\n",
        "    # run NATIONAL model (example: national average series)\n",
        "    res, used = ts_ols_modelB(nat_all, year_col=YEAR, p=p)\n",
        "\n",
        "    # cumulative effect (using the correct function for unemployment lags)\n",
        "    cum_eff = cumulative_unemp_effect(res, p)\n",
        "\n",
        "    # Wald test (using the correct function for unemployment lags)\n",
        "    # The function wald_pvalue_unemp_block expects the model results and p\n",
        "    wald_p_val = wald_pvalue_unemp_block(res, p)\n",
        "\n",
        "    # To get the statistic, we need to manually reconstruct the Wald test as wald_pvalue_unemp_block only returns p-value\n",
        "    terms = [f\"u_L{k}\" for k in range(0, p + 1)]\n",
        "    hypothesis = \" = \".join(terms) + \" = 0\"\n",
        "    wt = res.wald_test(hypothesis, scalar=True)\n",
        "    wald_stat = float(wt.statistic)\n",
        "\n",
        "    rows.append({\n",
        "        \"p\": p,\n",
        "        \"Cumulative unemployment effect\": cum_eff,\n",
        "        \"Wald stat\": wald_stat,\n",
        "        \"Wald p-value\": wald_p_val,\n",
        "        \"N\": int(res.nobs),\n",
        "    })\n",
        "\n",
        "# build table\n",
        "sens_table = pd.DataFrame(rows).set_index(\"p\")\n",
        "sens_table.index.name = \"k\"\n",
        "\n",
        "# pretty print\n",
        "with pd.option_context(\n",
        "    \"display.float_format\", lambda x: f\"{x:.6g}\",\n",
        "    \"display.width\", 2000\n",
        "):\n",
        "    print(sens_table)"
      ],
      "metadata": {
        "id": "IJpETwoVi5qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model B3: 8-region panel**"
      ],
      "metadata": {
        "id": "uMhTpwaNd6T-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\ln(Gambling_{i,t})\n",
        "=\n",
        "\\alpha\n",
        "+\\sum_{k=0}^{p}\\theta_k\\,Unemp_{i,t-k}\n",
        "+\\delta_2 \\ln(Pop_{i,t})\n",
        "+\\delta_3 WPI_{i,t}\n",
        "+\\mu_i\n",
        "+\\lambda_t\n",
        "+\\eta_{i,t}\n",
        "$$"
      ],
      "metadata": {
        "id": "GXd2Tb7kjBH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "H_0 &: \\sum_{k=0}^{p}\\theta_k = 0,\n",
        "&& k = 0,1,\\dots,p\n",
        "&& \\text{(No overall association over the lag window)} \\\\\n",
        "H_1 &: \\sum_{k=0}^{p}\\theta_k \\neq 0,\n",
        "&& k = 0,1,\\dots,p\n",
        "&& \\text{(Overall association over the lag window)}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "wBJ-EM24ZMVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model B (panel FE): log_gambling on lags of unemployment + controls (log_awe, log_pop, WPI)\n",
        "\n",
        "def panel_modelB(df_panel, *, p=1):\n",
        "\n",
        "\n",
        "    d = df_panel.copy()\n",
        "\n",
        "    # Ensure MultiIndex (STATE, YEAR)\n",
        "    if not isinstance(d.index, pd.MultiIndex):\n",
        "        d = d.set_index([STATE, YEAR]).sort_index()\n",
        "    else:\n",
        "        d = d.sort_index()\n",
        "\n",
        "    # Lags of unemployment within state: k = 0..p\n",
        "    for k in range(0, p + 1):\n",
        "        d[f\"u_L{k}\"] = d.groupby(level=0)[UNEMP].shift(k)\n",
        "\n",
        "    # Regressors: unemployment lags + controls\n",
        "    rhs = [f\"u_L{k}\" for k in range(0, p + 1)] + [ \"log_pop\", WPI]\n",
        "\n",
        "    # Keep complete cases\n",
        "    d = d.dropna(subset=[\"log_gambling\"] + rhs)\n",
        "\n",
        "    y = d[\"log_gambling\"].astype(float)\n",
        "    X = d[rhs].astype(float)\n",
        "\n",
        "    mod = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
        "    return mod.fit(cov_type=\"clustered\", cluster_entity=True)\n"
      ],
      "metadata": {
        "id": "ifS_h3GYItSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call panel\n",
        "resB_panel = panel_modelB(df, p=5)\n",
        "print(resB_panel.summary)"
      ],
      "metadata": {
        "id": "GH4Dl3j0jSQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PART 1 ‚Äî Panel FE Model B (reverse direction)\n",
        "#   log_gambling_{i,t} on unemployment lags + controls\n",
        "#   + cumulative effect + joint Wald test\n",
        "# =========================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from linearmodels.panel import PanelOLS\n",
        "\n",
        "def panel_fe_modelB(df_panel, *, p=1):\n",
        "    d = df_panel.copy()\n",
        "\n",
        "    # Ensure MultiIndex (STATE, YEAR)\n",
        "    if not isinstance(d.index, pd.MultiIndex):\n",
        "        d = d.set_index([STATE, YEAR]).sort_index()\n",
        "    else:\n",
        "        d = d.sort_index()\n",
        "\n",
        "    # Required columns\n",
        "    required = [\"log_gambling\", UNEMP, \"log_pop\", WPI]\n",
        "    missing = [c for c in required if c not in d.columns]\n",
        "    if missing:\n",
        "        raise KeyError(f\"Missing columns in df_panel: {missing}\")\n",
        "\n",
        "    # Lags of unemployment within state: k = 0..p\n",
        "    for k in range(0, p + 1):\n",
        "        d[f\"u_L{k}\"] = d.groupby(level=0)[UNEMP].shift(k)\n",
        "\n",
        "    # Regressors: unemployment lags + controls\n",
        "    u_terms = [f\"u_L{k}\" for k in range(0, p + 1)]\n",
        "    rhs = u_terms + [\"log_pop\", WPI]\n",
        "\n",
        "    # Keep complete cases (lags induce N drop)\n",
        "    d = d[[\"log_gambling\"] + rhs].dropna()\n",
        "\n",
        "    y = d[\"log_gambling\"].astype(float)\n",
        "    X = d[rhs].astype(float)\n",
        "\n",
        "    mod = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
        "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
        "\n",
        "    # ---- Cumulative effect: sum_{k=0..p} theta_k ----\n",
        "    cum_effect = float(res.params[u_terms].sum())\n",
        "\n",
        "    # ---- Joint Wald test: H0: u_L0 = ... = u_Lp = 0 ----\n",
        "    param_names = list(res.params.index)\n",
        "    K = len(param_names)\n",
        "    R = np.zeros((len(u_terms), K))\n",
        "    for i, term in enumerate(u_terms):\n",
        "        R[i, param_names.index(term)] = 1.0\n",
        "    q = np.zeros(len(u_terms))\n",
        "\n",
        "    wald = res.wald_test(R, q)\n",
        "    wald_stat = float(wald.stat)\n",
        "    wald_pval = float(wald.pval)\n",
        "\n",
        "    extra = pd.DataFrame(\n",
        "        {\n",
        "            \"Cumulative unemployment effect\": [cum_effect],\n",
        "            \"Wald stat (H0: u_L0..u_Lp = 0)\": [wald_stat],\n",
        "            \"Wald p-value (H0: u_L0..u_Lp = 0)\": [wald_pval],\n",
        "            \"N\": [int(res.nobs)],\n",
        "            \"p\": [int(p)],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return res, extra"
      ],
      "metadata": {
        "id": "DOO5-mu2dZHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- HOW TO CALL THE PANEL (choose one p) ----\n",
        "# Example: run Model B panel with p = 3\n",
        "resB_panel, extraB_panel = panel_fe_modelB(df, p=3)\n",
        "\n",
        "print(resB_panel.summary)\n",
        "print(extraB_panel.T.rename(columns={0: \"value\"}))"
      ],
      "metadata": {
        "id": "V49LU78IdcmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PART 2 ‚Äî Sensitivity test for Panel Model B over multiple p\n",
        "# =========================\n",
        "\n",
        "def sensitivity_test_panelB(df_panel, p_list=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)):\n",
        "    rows = []\n",
        "    for p in p_list:\n",
        "        _, extra = panel_fe_modelB(df_panel, p=p)\n",
        "        rows.append(extra)\n",
        "\n",
        "    out = pd.concat(rows, ignore_index=True).set_index(\"p\")\n",
        "    return out"
      ],
      "metadata": {
        "id": "GzZhcq0AdhzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- HOW TO CALL THE SENSITIVITY TEST ----\n",
        "# Example: test p = 1..5\n",
        "sensB = sensitivity_test_panelB(df, p_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
        "sensB"
      ],
      "metadata": {
        "id": "q0JfMTQndiUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the models in Section 3.1 only provide information about **correlation**. To further examine whether a **causal** relationship exists, we employ Granger causality analysis.\n",
        "\n",
        "What ‚ÄúGranger causality‚Äù actually means is not philosophical causality. Instead, it asks a specific and testable question:\n",
        "\n",
        "Do past values of gambling improve our ability to predict unemployment, over and above unemployment‚Äôs own past values?\n",
        "\n",
        "If yes, gambling is said to Granger-cause unemployment."
      ],
      "metadata": {
        "id": "n9czvECmmFxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But the good news is that Granger causality is much simpler than Section 3.1, where we used combined OLS and panel regression. For the panel analysis, we use the same equation and model structure for both national-level and regional-level data, and we simply switch the dependent and independent variables."
      ],
      "metadata": {
        "id": "Nu0BSPwtFH58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Conditional Granger causality tests\n",
        "\n",
        "3.2.C Model C: Gambling Granger-causes unemployment\n",
        "* supports gambling leads unemployment"
      ],
      "metadata": {
        "id": "KE-_yy2IyZCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "Unemp_t\n",
        "=\n",
        "\\alpha\n",
        "+\\sum_{k=1}^{p}\\gamma_k\\,Unemp_{t-k}\n",
        "+\\sum_{k=1}^{p}\\beta_k\\,\\ln(Gambling_{t-k})\n",
        "+\\delta_2 \\ln(Pop_t)\n",
        "+\\delta_3 WPI_t\n",
        "+\\epsilon_t\n",
        "$$"
      ],
      "metadata": {
        "id": "oU0kuvWFyWUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis**:\n"
      ],
      "metadata": {
        "id": "tOF5dSJT_DzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "H_0 &: \\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0\n",
        "&& \\text{(Lagged gambling has no predictive content for unemployment)} \\\\\n",
        "H_1 &: \\exists\\, k \\in \\{1,\\dots,p\\} \\text{ such that } \\beta_k \\neq 0\n",
        "&& \\text{(Lagged gambling has predictive content for unemployment)}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "TvSSR3c5TZg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def granger_gambling_to_unemp_joint(\n",
        "    ts_df,\n",
        "    *,\n",
        "    year_col=YEAR,\n",
        "    maxlag=4,\n",
        "    controls=(\"log_pop\", WPI)\n",
        "):\n",
        "    def stars(p):\n",
        "        if p < 0.01:\n",
        "            return \"***\"\n",
        "        if p < 0.05:\n",
        "            return \"**\"\n",
        "        if p < 0.1:\n",
        "            return \"*\"\n",
        "        return \"\"\n",
        "\n",
        "    cols = [year_col, UNEMP, \"log_gambling\", *controls]\n",
        "    d = ts_df[cols].dropna().sort_values(year_col).copy()\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for L in range(1, maxlag + 1):\n",
        "        tmp = d.copy()\n",
        "\n",
        "        # build lags\n",
        "        for k in range(1, L + 1):\n",
        "            tmp[f\"u_L{k}\"] = tmp[UNEMP].shift(k)\n",
        "            tmp[f\"g_L{k}\"] = tmp[\"log_gambling\"].shift(k)\n",
        "\n",
        "        tmp = tmp.dropna()\n",
        "\n",
        "        y = tmp[UNEMP].astype(float)\n",
        "\n",
        "        X = sm.add_constant(\n",
        "            tmp[[f\"u_L{k}\" for k in range(1, L + 1)] +\n",
        "                [f\"g_L{k}\" for k in range(1, L + 1)] +\n",
        "                list(controls)]\n",
        "            .astype(float)\n",
        "        )\n",
        "\n",
        "        res = sm.OLS(y, X).fit()\n",
        "\n",
        "        # joint F-test: all gambling lags = 0\n",
        "        param_names = list(X.columns) # Re-adding this line\n",
        "        # Fix: R should have L+1 rows to test g_L0, ..., g_LL\n",
        "        # Note: Granger causality typically tests only for lagged effects (k=1 to L), not contemporaneous (k=0).\n",
        "        # The current R definition and loop range for k (1 to L) correctly reflect this.\n",
        "        R = np.zeros((L, len(param_names))) # Changed back to L rows because `k` goes from 1 to L, so we test L parameters.\n",
        "        for i, k in enumerate(range(1, L + 1)): # k starts from 1, so indices in R will be 0 to L-1\n",
        "            R[i, param_names.index(f\"g_L{k}\")] = 1.0\n",
        "\n",
        "        ftest = res.f_test(R)\n",
        "\n",
        "        # cumulative direction\n",
        "        cum_coef = sum(res.params[f\"g_L{k}\"] for k in range(1, L + 1))\n",
        "\n",
        "        rows.append({\n",
        "            \"Lag\": L,\n",
        "            \"Cumulative gambling effect\": cum_coef,\n",
        "            \"Direction\": \"Positive\" if cum_coef > 0 else \"Negative\",\n",
        "            \"F_stat\": float(ftest.fvalue),\n",
        "            \"p_value\": float(ftest.pvalue),\n",
        "            \"N\": int(res.nobs)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "oBg8pFNfQBTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#national\n",
        "gc_nat = granger_gambling_to_unemp_joint(\n",
        "    nat_all,\n",
        "    year_col=YEAR,\n",
        "    maxlag=7\n",
        ")\n",
        "print(gc_nat)\n"
      ],
      "metadata": {
        "id": "QiS9E4ruQEsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regional\n",
        "# Corrected: Use .isin() for selecting multiple states\n",
        "region = df_flat[df_flat[\"State\"] == \"QLD\"][\n",
        "    [YEAR, UNEMP, \"log_gambling\", \"log_pop\", WPI]\n",
        "]\n",
        "\n",
        "gc_nsw = granger_gambling_to_unemp_joint(\n",
        "    region,\n",
        "    year_col=YEAR,\n",
        "    maxlag=5\n",
        ")\n",
        "print(gc_nsw)"
      ],
      "metadata": {
        "id": "sYn5Uj74efHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.D Model D2: Unemployment Granger-causes gambling\n",
        "* supports gambling lags unemployment"
      ],
      "metadata": {
        "id": "0AvTa8oPy3FM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\ln(Gambling_t)\n",
        "=\n",
        "\\alpha\n",
        "+\\sum_{k=1}^{p}\\phi_k\\,\\ln(Gambling_{t-k})\n",
        "+\\sum_{k=1}^{p}\\theta_k\\,Unemp_{t-k}\n",
        "+\\delta_2 \\ln(Pop_t)\n",
        "+\\delta_3 WPI_t\n",
        "+\\eta_t\n",
        "$$"
      ],
      "metadata": {
        "id": "tX2tWGa-ysUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "H_0 &: \\theta_1 = \\theta_2 = \\cdots = \\theta_p = 0\n",
        "&& \\text{(Lagged unemployment has no predictive content for gambling)} \\\\\n",
        "H_1 &: \\exists\\, k \\in \\{1,\\dots,p\\} \\text{ such that } \\theta_k \\neq 0\n",
        "&& \\text{(Lagged unemployment has predictive content for gambling)}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "js_jCbwsUHK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def granger_unemp_to_gambling_joint(\n",
        "    ts_df,\n",
        "    *,\n",
        "    year_col=YEAR,\n",
        "    maxlag=4,\n",
        "    controls=( \"log_pop\", WPI)\n",
        "):\n",
        "\n",
        "    cols = [year_col, UNEMP, \"log_gambling\", *controls]\n",
        "    d = ts_df[cols].dropna().sort_values(year_col).copy()\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for L in range(1, maxlag + 1):\n",
        "        tmp = d.copy()\n",
        "\n",
        "        # build lags\n",
        "        for k in range(1, L + 1):\n",
        "            tmp[f\"g_L{k}\"] = tmp[\"log_gambling\"].shift(k)\n",
        "            tmp[f\"u_L{k}\"] = tmp[UNEMP].shift(k)\n",
        "\n",
        "        tmp = tmp.dropna()\n",
        "\n",
        "        y = tmp[\"log_gambling\"].astype(float)\n",
        "\n",
        "        X = sm.add_constant(\n",
        "            tmp[[f\"g_L{k}\" for k in range(1, L + 1)] +\n",
        "                [f\"u_L{k}\" for k in range(1, L + 1)] +\n",
        "                list(controls)]\n",
        "            .astype(float)\n",
        "        )\n",
        "\n",
        "        res = sm.OLS(y, X).fit()\n",
        "\n",
        "        # joint F-test: all unemployment lags = 0\n",
        "        param_names = list(X.columns)\n",
        "        R = np.zeros((L, len(param_names)))\n",
        "        for i, k in enumerate(range(1, L + 1)):\n",
        "            R[i, param_names.index(f\"u_L{k}\")] = 1.0\n",
        "\n",
        "        ftest = res.f_test(R)\n",
        "\n",
        "        # cumulative direction\n",
        "        cum_coef = sum(res.params[f\"u_L{k}\"] for k in range(1, L + 1))\n",
        "\n",
        "        rows.append({\n",
        "            \"Lag\": L,\n",
        "            \"Cumulative unemployment effect\": cum_coef,\n",
        "            \"Direction\": \"Positive\" if cum_coef > 0 else \"Negative\",\n",
        "            \"F_stat\": float(ftest.fvalue),\n",
        "            \"p_value\": float(ftest.pvalue),\n",
        "            \"N\": int(res.nobs)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "0vX8HdIeRnkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gd_nat = granger_unemp_to_gambling_joint(\n",
        "    nat_all,\n",
        "    year_col=YEAR,\n",
        "    maxlag=5\n",
        ")\n",
        "print(gd_nat)\n"
      ],
      "metadata": {
        "id": "jXCkvL6QRtSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region = df_flat[df_flat[\"State\"] == \"TAS\"][\n",
        "    [YEAR, UNEMP, \"log_gambling\", \"log_pop\", WPI]\n",
        "]\n",
        "\n",
        "gd_nsw = granger_unemp_to_gambling_joint(\n",
        "    region,\n",
        "    year_col=YEAR,\n",
        "    maxlag=5\n",
        ")\n",
        "print(gd_nsw)\n"
      ],
      "metadata": {
        "id": "4PAlS0kMRwWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarise, we have two parts in our method.\n",
        "\n",
        "Part $1$ tests for correlation using time-series OLS (national and regional) and panel regression (national).\n",
        "\n",
        "Part $2$ tests for causation using Granger causality (national and regional)."
      ],
      "metadata": {
        "id": "Yt8e1h8EGDBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please tell me anything you think may be we should add or delete:), also here are some things to think about:\n",
        "\n",
        "\n",
        "I am thinking about may be choose one from Times-series OLS at the national level and panel regression at the national level, maybe we should subtract the OLS at national level?\n"
      ],
      "metadata": {
        "id": "6fUVu6XQHmC8"
      }
    }
  ]
}